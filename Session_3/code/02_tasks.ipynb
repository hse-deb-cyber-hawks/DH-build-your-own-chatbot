{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Simple vector embedding generation\n",
    "\n",
    "**Objective:**\n",
    "Generate vector embeddings from text data.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- load embedding model into ollama:\n",
    "    1. Attach ollama container shell\n",
    "    2. Run command in container `ollama pull pull bge-m3` or send an api call `requests.post(\"http://localhost:11434/api/pull\", json = {\"name\": \"bge-m3\",  \"stream\": False}` via the requests library to download embedding model.\n",
    "- embed simple text queries\n",
    "\n",
    "How to select the right embedding model: [MTEB - Massive Text Embedding Benchmark](https://huggingface.co/blog/mteb)\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [Ollama REST API](https://www.postman.com/postman-student-programs/ollama-api/documentation/suc47x8/ollama-rest-api)\n",
    "- [Langchain Ollama Embeddings](https://python.langchain.com/docs/integrations/text_embedding/ollama/)\n",
    "- [Langchain Chroma](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download embedding model into ollama container\n",
    "requests.post(\"http://localhost:11434/api/pull\", json = {\"name\": \"bge-m3\",  \"stream\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available models in the ollama container\n",
    "response = requests.get(\"http://localhost:11434/api/ps\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector length: 1024\n",
      "[-0.050015017, 0.021115491, -0.05706942, -0.005513766, -0.0062966477, -0.028438922, 0.04517284, 0.042702336, -0.0002470305, 0.013070632]\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a test document.\"\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Perform vector search\n",
    "query_vector = embedding_model.embed_query(text)\n",
    "\n",
    "print(f\"Embedding vector length: {len(query_vector)}\")\n",
    "print(query_vector[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Generate embedding vectors with custom dataset\n",
    "\n",
    "**Objective:**\n",
    "Load custom dataset, preprocess it and generate vector embeddings.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- load pdf document \"AI_Book.pdf\" via langchain document loader: ``PyPDFLoader``\n",
    "- use RecursiveCharacterTextSplitter to split documents into chunks\n",
    "- generate embeddings for single documents\n",
    "\n",
    "**RecursiveCharacterTextSplitter:**\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is `[\"\\n\\n\", \"\\n\", \" \", \"\"]`. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [Langchain PyPDFLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html)\n",
    "- [Langchain RecursiveCharacterTextSplitter](https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Aurélien Géron\n",
      "Hands-on Machine Learning with\n",
      "Scikit-Learn, Keras, and\n",
      "TensorFlow\n",
      "Concepts, Tools, and Techniques to\n",
      "Build Intelligent Systems\n",
      "SECOND EDITION\n",
      "Boston Farnham Sebastopol TokyoBeijing Boston Farnham Sebastopol TokyoBeijing' metadata={'source': './AI_Book.pdf', 'page': 2}\n",
      "page_content='Aurlien Gron\n",
      "Hands-on Machine Learning with\n",
      "Scikit-Learn, Keras, and\n",
      "TensorFlow\n",
      "Concepts, Tools, and Techniques to\n",
      "Build Intelligent Systems\n",
      "SECOND EDITION\n",
      "Boston Farnham Sebastopol TokyoBeijing Boston Farnham Sebastopol TokyoBeijing' metadata={'source': './AI_Book.pdf', 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.schema import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "\n",
    "pdf_doc = \"./AI_Book.pdf\"\n",
    "\n",
    "# Create pdf data loader\n",
    "# ADD HERE YOUR CODE\n",
    "pdf_doc = \"./AI_Book.pdf\"\n",
    "loader = PyPDFLoader(pdf_doc)\n",
    "\n",
    "# Load and split documents in chunks\n",
    "# ADD HERE YOUR CODE\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=150, \n",
    "    strip_whitespace=True\n",
    ")\n",
    "pages_chunked = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "print(pages_chunked[0])\n",
    "\n",
    "# Function to clean text by removing invalid unicode characters, including surrogate pairs\n",
    "def clean_text(text):\n",
    "    # Remove surrogate pairs\n",
    "    text = re.sub(r'[\\ud800-\\udfff]', '', text)\n",
    "    # Optionally remove non-ASCII characters (depends on your use case)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    return text\n",
    "\n",
    "pages_chunked_cleaned = [\n",
    "    Document(page_content=clean_text(doc.page_content), metadata=doc.metadata)\n",
    "    for doc in pages_chunked\n",
    "]\n",
    "\n",
    "print(pages_chunked_cleaned[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='978-1-492-03264-9\n",
      "[LSI]\n",
      "Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow\n",
      "by Aurlien Gron\n",
      "Copyright  2019 Aurlien Gron. All rights reserved.\n",
      "Printed in the United States of America.\n",
      "Published by OReilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.\n",
      "OReilly books may be purchased for educational, business, or sales promotional use. Online editions are\n",
      "also available for most titles (http://oreilly.com). For more information, contact our corporate/institutional\n",
      "sales department: 800-998-9938 or corporate@oreilly.com.\n",
      "Editor: Nicole Tache\n",
      "Interior Designer: David Futato\n",
      "Cover Designer: Karen Montgomery\n",
      "Illustrator: Rebecca Demarest\n",
      "June 2019:  Second Edition\n",
      "Revision History for the Early Release\n",
      "2018-11-05: First Release\n",
      "2019-01-24: Second Release\n",
      "2019-03-07: Third Release\n",
      "2019-03-29: Fourth Release\n",
      "2019-04-22: Fifth Release\n",
      "See http://oreilly.com/catalog/errata.csp?isbn=9781492032649 for release details.' metadata={'source': './AI_Book.pdf', 'page': 3}\n"
     ]
    }
   ],
   "source": [
    "print(pages_chunked_cleaned[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 1286\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of text chunks: {len(pages_chunked_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Store vector embeddings from pdf document to ChromaDB vector database.\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Store vector embeddings into ChromaDB to store knowledge.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- create chromadb client\n",
    "- create chromadb collection\n",
    "- create langchain chroma db client\n",
    "- store text document chunks and vector embeddings to vector databases\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [Langchain How To](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/#initialization-from-client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "{\"detail\":\"Not Found\"} (trace ID: 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\chromadb\\api\\base_http_client.py:99\u001b[39m, in \u001b[36mBaseHTTPClient._raise_chroma_error\u001b[39m\u001b[34m(resp)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '404 Not Found' for url 'http://localhost:8000/api/v2/auth/identity'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\chromadb\\api\\client.py:101\u001b[39m, in \u001b[36mClient.get_user_identity\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_user_identity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:150\u001b[39m, in \u001b[36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity < granularity:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\chromadb\\api\\fastapi.py:144\u001b[39m, in \u001b[36mFastAPI.get_user_identity\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFastAPI.get_user_identity\u001b[39m\u001b[33m\"\u001b[39m, OpenTelemetryGranularity.OPERATION)\n\u001b[32m    142\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_user_identity\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> UserIdentity:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m UserIdentity(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/auth/identity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\chromadb\\api\\fastapi.py:90\u001b[39m, in \u001b[36mFastAPI._make_request\u001b[39m\u001b[34m(self, method, path, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m response = \u001b[38;5;28mself\u001b[39m._session.request(method, url, **cast(Any, kwargs))\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[43mBaseHTTPClient\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_raise_chroma_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m orjson.loads(response.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\chromadb\\api\\base_http_client.py:103\u001b[39m, in \u001b[36mBaseHTTPClient._raise_chroma_error\u001b[39m\u001b[34m(resp)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trace_id:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (trace ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrace_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m(resp.text))\n",
      "\u001b[31mException\u001b[39m: {\"detail\":\"Not Found\"} (trace ID: 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m client = \u001b[43mchromadb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHttpClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlocalhost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallow_reset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manonymized_telemetry\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEFAULT_TENANT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEFAULT_DATABASE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m collection_name = \u001b[33m\"\u001b[39m\u001b[33mai_model_book\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# ADD HERE YOUR CODE\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Create a collection\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\chromadb\\__init__.py:204\u001b[39m, in \u001b[36mHttpClient\u001b[39m\u001b[34m(host, port, ssl, headers, settings, tenant, database)\u001b[39m\n\u001b[32m    201\u001b[39m settings.chroma_server_ssl_enabled = ssl\n\u001b[32m    202\u001b[39m settings.chroma_server_headers = headers\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\chromadb\\api\\client.py:65\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, tenant, database, settings)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Get the root system component we want to interact with\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m._server = \u001b[38;5;28mself\u001b[39m._system.instance(ServerAPI)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m user_identity = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_user_identity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m maybe_tenant, maybe_database = maybe_set_tenant_and_database(\n\u001b[32m     68\u001b[39m     user_identity,\n\u001b[32m     69\u001b[39m     overwrite_singleton_tenant_database_access_from_auth=settings.chroma_overwrite_singleton_tenant_database_access_from_auth,\n\u001b[32m     70\u001b[39m     user_provided_tenant=tenant,\n\u001b[32m     71\u001b[39m     user_provided_database=database,\n\u001b[32m     72\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maybe_tenant:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\chromadb\\api\\client.py:110\u001b[39m, in \u001b[36mClient.get_user_identity\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[31mValueError\u001b[39m: {\"detail\":\"Not Found\"} (trace ID: 0)"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "import chromadb\n",
    "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
    "\n",
    "client = chromadb.HttpClient(\n",
    "    host=\"localhost\",\n",
    "    port=8000,\n",
    "    ssl=False,\n",
    "    headers=None,\n",
    "    settings=Settings(allow_reset=True, anonymized_telemetry=False),\n",
    "    tenant=DEFAULT_TENANT,\n",
    "    database=DEFAULT_DATABASE,\n",
    ")\n",
    "\n",
    "collection_name = \"ai_model_book\"\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create a collection\n",
    "try:\n",
    "    client.delete_collection(name=collection_name)\n",
    "    print(f\"Alte Collection '{collection_name}' gelöscht.\")\n",
    "except Exception:\n",
    "    print(f\"Keine alte Collection '{collection_name}' gefunden. Fahre fort.\")\n",
    "\n",
    "collection = client.get_or_create_collection(name=collection_name)\n",
    "print(f\"Collection '{collection_name}' ist bereit.\")\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create chromadb\n",
    "vector_db_from_client = Chroma(client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pages_chunked_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muuid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m uuid4\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m uuids = [\u001b[38;5;28mstr\u001b[39m(uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mpages_chunked_cleaned\u001b[49m))]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# ADD HERE YOUR CODE\u001b[39;00m\n\u001b[32m      6\u001b[39m vector_db_from_client.add_documents(documents=pages_chunked_cleaned, \n\u001b[32m      7\u001b[39m     ids=uuids) \u001b[38;5;66;03m# that can take a while...\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'pages_chunked_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(pages_chunked_cleaned))]\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "vector_db_from_client.add_documents(documents=pages_chunked_cleaned, \n",
    "    ids=uuids) # that can take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mclient\u001b[49m.count_collections()\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "client.count_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.delete_collection(\"ai_model_book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get and check the content of the collection\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mcollection\u001b[49m.get(include=[\u001b[33m\"\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmetadatas\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'collection' is not defined"
     ]
    }
   ],
   "source": [
    "# Get and check the content of the collection\n",
    "collection.get(include=[\"documents\", \"metadatas\", \"embeddings\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Access ChromaDB and perform vector search\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Use query to perform vector search against ChromaDB vector database\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- define query\n",
    "- run vector search\n",
    "- print k=3 most similar documents\n",
    "\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [Langchain Query ChromaDB](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/#query-directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"Types of Machine Learning Systems\"\n",
    "\n",
    "results = vector_db_from_client.similarity_search(query=search_query, k=3)\n",
    "\n",
    "for res in results:\n",
    "    print(res.page_content)\n",
    "    print(res.metadata)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
