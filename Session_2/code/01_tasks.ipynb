{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
=======
   "execution_count": 1,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Create a Simple Chain for Summarization\n",
    "\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Build a LangChain chain that can summarize a given text.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Create a llm chain using with a Ollama model.\n",
    "- Define a prompt template for summarization. The summary should be only one sentence.\n",
    "- Run the chain with a sample text and print the summary.\n",
    "- Add model output streaming.\n",
    "- Run the chain with streaming with a sample text and print the summary.\n",
    "\n",
    "\n",
    "**Hint: The five messages in LangChain:**\n",
    "\n",
    "\n",
    "- SystemMessage: corresponds to system role\n",
    "- HumanMessage: corresponds to user role\n",
    "- AIMessage: corresponds to assistant role\n",
    "- AIMessageChunk: corresponds to assistant role, used for streaming responses\n",
    "- ToolMessage: corresponds to tool role\n",
    "\n",
    "\n",
    "[More Information](https://python.langchain.com/docs/concepts/messages/)\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To Prompt Template 1](https://python.langchain.com/v0.2/docs/tutorials/extraction/#the-extractor)\n",
    "- [How To Prompt Template 2](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "- [How To LCEL Chains 1](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel)\n",
    "- [How To LCEL Chains 2](https://python.langchain.com/v0.2/docs/versions/migrating_chains/llm_chain/#lcel)\n",
    "- [How To Chain Streaming](https://python.langchain.com/v0.2/docs/concepts/#streaming)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 4,
=======
   "execution_count": 2,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Deep learning has undergone significant evolution over the past decade, becoming increasingly popular with large language models (LLMs) that have a broad range of applications and are poised to have a major impact on various industries and aspects of society.\n"
=======
      "Deep learning has undergone significant evolution over the past decade, driving mass popularity of artificial intelligence models in various industries.\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load the Ollama model\n",
    "llm = ChatOllama(model=model)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Define the prompt template\n",
    "summarization_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Summarize the following text in exactly one sentence.\"), # <-- LÖSUNG\n",
    "    (\"human\", \"{text}\"),\n",
    "])\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create the LLMChain\n",
    "summarization_chain = summarization_prompt | llm\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"Over the last decade, deep learning has evolved massively to process and generate unstructured data like text, images, and video. \n",
    "These advanced AI models have gained popularity in various industries, and include large language models (LLMs). \n",
    "There is currently a significant level of fanfare in both the media and the industry surrounding AI,\n",
    "and there’s a fair case to be made that Artificial Intelligence (AI), with these advancements,\n",
    "is about to have a wide-ranging and major impact on businesses, societies, and individuals alike.\n",
    "This is driven by numerous factors, including advancements in technology, high-profile applications, \n",
    "and the potential for transfor- mative impacts across multiple sectors.\"\"\"\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Invoke the chain\n",
    "summary = summarization_chain.invoke({\"text\": text})\n",
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 5,
=======
   "execution_count": 3,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Deep learning has revolutionized industries with large language models, such as AI, which are expected to have a significant impact on businesses, societies, and individuals worldwide."
=======
      "Deep learning has experienced significant evolution over the last decade, driven by technological advancements, media attention, and a range of transformative implications that are expected to have far-reaching effects on various industries and aspects of society."
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "# Stream the chain output\n",
    "for chunk in summarization_chain.stream({\"text\": text}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Chain with Tool Usage (Simple Math Tool)\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Create a LangChain chain that uses a simple math tool to perform calculations.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Define a function as tool which multiplies two integer values and return the result.\n",
    "- Create a chain\n",
    "- Print the result of the calculation.\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To Tools](https://python.langchain.com/v0.2/docs/how_to/tools_chain/#create-a-tool)\n",
    "- [How To Tools in Chains](https://python.langchain.com/v0.2/docs/how_to/tools_chain/#chains)\n",
    "- [How To Tool Calling](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling)\n",
    "- [How To Chain and Call Tools with Ollama](https://python.langchain.com/v0.2/docs/integrations/chat/ollama/)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 7,
=======
   "execution_count": 4,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiplies two integers and returns the result.\n",
      "{'first_int': {'title': 'First Int', 'type': 'integer'}, 'second_int': {'title': 'Second Int', 'type': 'integer'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 7,
=======
     "execution_count": 4,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create custom tool\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiplies two integers and returns the result.\"\"\"\n",
    "    return first_int * second_int\n",
    "\n",
    "\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args) # -> definition of tool arguments\n",
    "\n",
    "# Invoke custom tool\n",
    "multiply.invoke({\"first_int\": 4, \"second_int\": 5})"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 8,
=======
   "execution_count": 5,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "[{'name': 'multiply', 'args': {'first_int': '42', 'second_int': '5'}, 'id': '0dd42a47-e27a-4958-8cf8-a004d48d3493', 'type': 'tool_call'}]\n"
=======
      "[{'name': 'multiply', 'args': {'first_int': '42', 'second_int': '5'}, 'id': '0b3438b7-c03b-4d39-9211-4f003b9208fd', 'type': 'tool_call'}]\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "# Load the Ollama model\n",
    "llm = ChatOllama(model=model)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Use bind_tools to pass the definition of our tool in as part of each call to the model, so that the model can invoke the tool\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "# When the model invokes the tool, this will show up in the AIMessage.tool_calls attribute of the output -> extract tool parameters from input text\n",
    "msg = llm_with_tools.invoke(\"whats 5 times forty two\")\n",
    "print(msg.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 9,
=======
   "execution_count": 6,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 9,
=======
     "execution_count": 6,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD HERE YOUR CODE\n",
    "# Create the chain: pass the extracte tool parameters from the input text to the tool -> extract the arguments of the first tool_call\n",
    "chain_with_tools = llm_with_tools | (lambda msg: msg.tool_calls[0]['args']) | multiply\n",
    "\n",
    "# Run chain\n",
    "chain_with_tools.invoke(\"whats 5 times forty two\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Agent with Tool Usage (Two Tools)\n",
    "\n",
    "**Objective:** \n",
    "\n",
    "Create a LangChain agent that uses two tools to perform tasks.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Define prompt template.\n",
    "- Define tools.\n",
    "- Create an Agent using the Ollama model, prompt template and tools.\n",
    "- Run the agent with a prompt that requires one or both tools.\n",
    "- Observe how the agent uses the tools to complete the task.\n",
    "\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To 1](https://python.langchain.com/v0.2/docs/concepts/#agents)\n",
    "- [How To 2](https://python.langchain.com/v0.2/docs/how_to/tools_chain/#agents)\n",
    "- [How To 3](https://python.langchain.com/v0.2/docs/tutorials/agents/)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 18,
=======
   "execution_count": 7,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AgentExecutor' from 'langchain.agents' (c:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\langchain\\agents\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
<<<<<<< Updated upstream
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgentExecutor, create_tool_calling_agent\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load the Ollama model\u001b[39;00m\n\u001b[32m      4\u001b[39m llm = ChatOllama(model=model)\n",
=======
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgentExecutor, create_tool_calling_agent\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load the Ollama model\u001b[39;00m\n\u001b[32m      4\u001b[39m llm = ChatOllama(model=model)\n",
>>>>>>> Stashed changes
      "\u001b[31mImportError\u001b[39m: cannot import name 'AgentExecutor' from 'langchain.agents' (c:\\Users\\Leina\\OneDrive\\Uni\\3 Semester\\Technische Informatik\\Labor\\DH-build-your-own-chatbot\\.venv\\Lib\\site-packages\\langchain\\agents\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "# Load the Ollama model\n",
    "llm = ChatOllama(model=model)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can use tools to calculate.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# Custom math tools\n",
    "@tool\n",
    "def add(first_int: int, second_int: int) -> int:\n",
    "    \"Add two integers.\"\n",
    "    return first_int + second_int\n",
    "\n",
    "\n",
    "@tool\n",
    "def exponentiate(base: int, exponent: int) -> int:\n",
    "    \"Exponentiate the base to the exponent power.\"\n",
    "    return base**exponent\n",
    "\n",
    "\n",
    "tools = [add, exponentiate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_tool_calling_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ADD HERE YOUR CODE\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Construct the tool calling agent\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m agent_with_tools = \u001b[43mcreate_tool_calling_agent\u001b[49m(llm, tools, agent_prompt)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# ADD HERE YOUR CODE\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Create an agent executor by passing in the agent and tools\u001b[39;00m\n\u001b[32m      7\u001b[39m agent_executor_with_tools = AgentExecutor(\n\u001b[32m      8\u001b[39m     agent=agent_with_tools, \n\u001b[32m      9\u001b[39m     tools=tools, \n\u001b[32m     10\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     11\u001b[39m ) \n",
      "\u001b[31mNameError\u001b[39m: name 'create_tool_calling_agent' is not defined"
     ]
    }
   ],
   "source": [
    "# ADD HERE YOUR CODE\n",
    "# Construct the tool calling agent\n",
    "agent_with_tools = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor_with_tools = AgentExecutor(\n",
    "    agent=agent_with_tools, \n",
    "    tools=tools, \n",
    "    verbose=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_executor_with_tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent_executor_with_tools\u001b[49m.invoke(\n\u001b[32m      2\u001b[39m     {\n\u001b[32m      3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33muser_input\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mFirst take 3 to the power of five and afterwards add 12.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m     }\n\u001b[32m      5\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'agent_executor_with_tools' is not defined"
     ]
    }
   ],
   "source": [
    "agent_executor_with_tools.invoke(\n",
    "    {\n",
    "        \"user_input\": \"First take 3 to the power of five and afterwards add 12.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Optional] Task 4: Enhance Agent with Memory\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Eenhance the agent from Task 3 with memory to improve its context awareness and ability to maintain state.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Create a ConversationBufferMemory to store chat history.\n",
    "- Modify the agent to use the memory to inform its responses.\n",
    "- Run the agent with a series of prompts that require context or state to be maintained.\n",
    "- Observe how the agent's responses improve with the addition of memory.\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To Memory 1](https://python.langchain.com/v0.2/api_reference/langchain/memory/langchain.memory.buffer.ConversationBufferMemory.html#langchain.memory.buffer.ConversationBufferMemory)\n",
    "- [How To Memory 1](https://python.langchain.com/v0.2/docs/versions/migrating_chains/conversation_chain/#legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.memory'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConversationBufferMemory\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MessagesPlaceholder\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the Ollama model\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.memory'"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# Load the Ollama model\n",
    "llm = ChatOllama(model=model)\n",
    "\n",
    "# Define memory object for conversation history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"output\")\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Add history placeholder to prompt\n",
    "agent_prompt_with_memory = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. You use tools and remember the conversation.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Construct the tool calling agent\n",
    "agent_with_tools_and_memory = create_tool_calling_agent(\n",
    "    llm, \n",
    "    tools, \n",
    "    agent_prompt_with_memory\n",
    ")\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor_with_tools_and_memory = AgentExecutor(\n",
    "    agent=agent_with_tools_and_memory,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_executor_with_tools_and_memory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mTake 3 to the fifth power then add that 12?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ai_msg_1 = \u001b[43magent_executor_with_tools_and_memory\u001b[49m.invoke({\u001b[33m\"\u001b[39m\u001b[33muser_input\u001b[39m\u001b[33m\"\u001b[39m: question})\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(ai_msg_1[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      5\u001b[39m second_question = \u001b[33m\"\u001b[39m\u001b[33mExplain how you have calculated the result.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'agent_executor_with_tools_and_memory' is not defined"
     ]
    }
   ],
   "source": [
    "question = \"Take 3 to the fifth power then add that 12?\"\n",
    "ai_msg_1 = agent_executor_with_tools_and_memory.invoke({\"user_input\": question})\n",
    "print(ai_msg_1[\"output\"])\n",
    "\n",
    "second_question = \"Explain how you have calculated the result.\"\n",
    "ai_msg_2 = agent_executor_with_tools_and_memory.invoke({\"user_input\": second_question})\n",
    "print(ai_msg_2[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
